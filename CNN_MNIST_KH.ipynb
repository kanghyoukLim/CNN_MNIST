{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0cb2eb-8f91-4835-a65c-7507bfaa1bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI-space\\anaconda3\\envs\\ve_torch\\lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28])\n",
      "torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# some_digit = X.to_numpy()[0]\n",
    "# some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "# plt.imshow(X[0].reshape(28,28), cmap='gray')\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "# print(\"이미지 레이블 : {}\".format(y[0]))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=1/7, random_state=0)\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(list(map(int, y_train)))\n",
    "y_test = torch.LongTensor(list(map(int, y_test)))\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "X_train = X_train.view(-1,1,28,28).float()\n",
    "X_test = X_test.view(-1,1,28,28).float()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "train = TensorDataset(X_train, y_train)\n",
    "test = TensorDataset(X_test, y_test)\n",
    "BATCH_SIZE = 32\n",
    "loader_train = DataLoader(train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "loader_test = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e5c6bf6-058e-4257-bfa7-de2de0d3b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "    # def__init__(self):\n",
    "        # super(CNN, self).__init__()\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32,32,kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64,kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64,256)\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1,3*3*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90cff4bb-fd75-4ba9-8c26-6b2141f55bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 정확도: 0.097%\n",
      "에포크 : 0[0/1875(0%)]\t 손실함수 : 19.511736\t Accuracy:6.250%\n",
      "에포크 : 0[1600/1875(3%)]\t 손실함수 : 1.804719\t Accuracy:17.034%\n",
      "에포크 : 0[3200/1875(5%)]\t 손실함수 : 1.533408\t Accuracy:31.714%\n",
      "에포크 : 0[4800/1875(8%)]\t 손실함수 : 1.226972\t Accuracy:42.156%\n",
      "에포크 : 0[6400/1875(11%)]\t 손실함수 : 0.573291\t Accuracy:49.052%\n",
      "에포크 : 0[8000/1875(13%)]\t 손실함수 : 0.479363\t Accuracy:54.046%\n",
      "에포크 : 0[9600/1875(16%)]\t 손실함수 : 0.629628\t Accuracy:58.191%\n",
      "에포크 : 0[11200/1875(19%)]\t 손실함수 : 0.484747\t Accuracy:61.663%\n",
      "에포크 : 0[12800/1875(21%)]\t 손실함수 : 0.696411\t Accuracy:64.090%\n",
      "에포크 : 0[14400/1875(24%)]\t 손실함수 : 0.403287\t Accuracy:66.512%\n",
      "에포크 : 0[16000/1875(27%)]\t 손실함수 : 0.304790\t Accuracy:68.463%\n",
      "에포크 : 0[17600/1875(29%)]\t 손실함수 : 0.245539\t Accuracy:70.219%\n",
      "에포크 : 0[19200/1875(32%)]\t 손실함수 : 0.513470\t Accuracy:71.683%\n",
      "에포크 : 0[20800/1875(35%)]\t 손실함수 : 0.511329\t Accuracy:73.037%\n",
      "에포크 : 0[22400/1875(37%)]\t 손실함수 : 0.086918\t Accuracy:74.238%\n",
      "에포크 : 0[24000/1875(40%)]\t 손실함수 : 0.441487\t Accuracy:75.208%\n",
      "에포크 : 0[25600/1875(43%)]\t 손실함수 : 0.311452\t Accuracy:76.127%\n",
      "에포크 : 0[27200/1875(45%)]\t 손실함수 : 0.242408\t Accuracy:77.038%\n",
      "에포크 : 0[28800/1875(48%)]\t 손실함수 : 0.172987\t Accuracy:77.893%\n",
      "에포크 : 0[30400/1875(51%)]\t 손실함수 : 0.230850\t Accuracy:78.611%\n",
      "에포크 : 0[32000/1875(53%)]\t 손실함수 : 0.297558\t Accuracy:79.280%\n",
      "에포크 : 0[33600/1875(56%)]\t 손실함수 : 0.418298\t Accuracy:79.891%\n",
      "에포크 : 0[35200/1875(59%)]\t 손실함수 : 0.045085\t Accuracy:80.455%\n",
      "에포크 : 0[36800/1875(61%)]\t 손실함수 : 0.633859\t Accuracy:80.970%\n",
      "에포크 : 0[38400/1875(64%)]\t 손실함수 : 0.206621\t Accuracy:81.458%\n",
      "에포크 : 0[40000/1875(67%)]\t 손실함수 : 0.246648\t Accuracy:81.865%\n",
      "에포크 : 0[41600/1875(69%)]\t 손실함수 : 0.156535\t Accuracy:82.256%\n",
      "에포크 : 0[43200/1875(72%)]\t 손실함수 : 0.024805\t Accuracy:82.649%\n",
      "에포크 : 0[44800/1875(75%)]\t 손실함수 : 0.310870\t Accuracy:83.026%\n",
      "에포크 : 0[46400/1875(77%)]\t 손실함수 : 0.088918\t Accuracy:83.408%\n",
      "에포크 : 0[48000/1875(80%)]\t 손실함수 : 0.830438\t Accuracy:83.755%\n",
      "에포크 : 0[49600/1875(83%)]\t 손실함수 : 0.178451\t Accuracy:84.022%\n",
      "에포크 : 0[51200/1875(85%)]\t 손실함수 : 0.063640\t Accuracy:84.309%\n",
      "에포크 : 0[52800/1875(88%)]\t 손실함수 : 0.265959\t Accuracy:84.566%\n",
      "에포크 : 0[54400/1875(91%)]\t 손실함수 : 0.365298\t Accuracy:84.836%\n",
      "에포크 : 0[56000/1875(93%)]\t 손실함수 : 0.123067\t Accuracy:85.092%\n",
      "에포크 : 0[57600/1875(96%)]\t 손실함수 : 0.033955\t Accuracy:85.362%\n",
      "에포크 : 0[59200/1875(99%)]\t 손실함수 : 0.227589\t Accuracy:85.602%\n",
      "테스트 데이터 정확도: 0.967%\n",
      "10 번째 학습데이터의 테스트 결과 : tensor([[-9.5287e+00, -3.5585e-03, -8.6848e+00, -9.4115e+00, -6.5412e+00,\n",
      "         -9.6195e+00, -9.4390e+00, -7.4062e+00, -7.9219e+00, -7.3089e+00]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "10번째 데이터의 예측:[1]\n",
      "실제 레이블:1\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "torch.nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')\n",
    "\n",
    "def fit(model, loader_train):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 1\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(loader_train):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            predicted = torch.max(output.data, 1)[1]\n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('에포크 : {}[{}/{}({:.0f}%)]\\t 손실함수 : {:.6f}\\t Accuracy:{:.3f}%'.format(epoch, batch_idx*len(X_batch),len(loader_train),100.*batch_idx/len(loader_train),loss.data, correct*100./(BATCH_SIZE*(batch_idx+1))))\n",
    "\n",
    "def evaluate(model):\n",
    "    correct = 0\n",
    "    for test_imgs, test_labels in loader_test:\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"테스트 데이터 정확도: {:.3f}%\".format(float(correct)/(len(loader_test)*BATCH_SIZE)))\n",
    "cnn = CNN()\n",
    "evaluate(cnn)\n",
    "fit(cnn, loader_train)\n",
    "cnn.eval()\n",
    "evaluate(cnn)\n",
    "index = 10\n",
    "data = X_test[index].view(-1,1,28,28).float()\n",
    "output = cnn(data)\n",
    "print('{} 번째 학습데이터의 테스트 결과 : {}'.format(index, output))\n",
    "predicted = torch.max(output, 1)\n",
    "print('{}번째 데이터의 예측:{}'.format(index, predicted[1].numpy()))\n",
    "print('실제 레이블:{}'.format(y_test[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a731b29-3bb1-40a4-b632-6dce3134cab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve_torch_kernel",
   "language": "python",
   "name": "ve_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
